{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974de014-c29a-4310-aab1-6e70d767595e",
   "metadata": {},
   "source": [
    "### What's scaCy?\n",
    "\n",
    "`spaCy is a free,open-source library for advanced Natural Language Programming(NLP) in python`\n",
    "\n",
    "spaCy is designed specifically for production use and helps you build applications that process and \"understand\" large values of text.It can be used to build information extraction or natural language understanding systensm or to pre-processing text for deep learning.\n",
    "\n",
    "\n",
    "spaCy is not a platform or an API software as a service or a web application.Its an opens-source library designed to help to build NLP applications, not a consumable service \n",
    "\n",
    "\n",
    "**Features**\n",
    "-------------\n",
    "Name           \n",
    "-------------\n",
    "* Tokenization --> Segmenting text into words,punctuations marks etc\n",
    "* Part-of-speech (POS) Tagging --> Assigning word types to tokens, like verb or noun\n",
    "* Dependency Parsing --> Assigning the base forms of words.For example, the lemma of \"was\" is \"be\" and the lemma of \"rats\" is \"rat\"\n",
    "* Sentence Boundary Detection (SBD) --> Finding and sengenting individual sentences.\n",
    "* Named Entity Recognition (NER)  --> Labelling named \"real-word\" objects. like parsons, companies or locations etc\n",
    "\n",
    "* Entity Linking (EL) --> Disambiguating textual entities to unique identifiers in a knowledge base.\n",
    "* Similarity --> Comparing words, text spans and documents and how similar they are to each other.\n",
    "* Text Classification --> Assigning categories or labels to a whole document, or parts of a document.\n",
    "* Rule-based Matching --> Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\n",
    "* Training --> Updating and improving a statistical modelâ€™s predictions.\n",
    "* Serialization --> Saving objects to files or byte strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfdc9fd-b6f6-49df-b174-1b43be32b3cb",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9d0ab27-a441-4baa-82f4-4172f3d042a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416eee1e-d0ae-4b5c-87eb-eaf1315c6090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My name is sujon.I am a software engineer"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"My name is sujon.I am a software engineer\"\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17b0363-ec93-472b-9f59-13b4755b6872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My\n",
      "name\n",
      "is\n",
      "sujon\n",
      ".\n",
      "I\n",
      "am\n",
      "a\n",
      "software\n",
      "engineer\n"
     ]
    }
   ],
   "source": [
    "# This line prints out the text of the token\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37a579bd-cf2b-463a-bffc-ce0b25cbcde6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenize text to parts of speech\n",
      "\n",
      "My : PRON\n",
      "name : NOUN\n",
      "is : AUX\n",
      "sujon : NOUN\n",
      ". : PUNCT\n",
      "I : PRON\n",
      "am : AUX\n",
      "a : DET\n",
      "software : NOUN\n",
      "engineer : NOUN\n"
     ]
    }
   ],
   "source": [
    "# Its part of speech\n",
    "print(\"tokenize text to parts of speech\\n\")\n",
    "for token in doc:\n",
    "    print(token.text,\":\",token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6183899e-b5d3-48ee-8e78-1b6e1185238d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My : PRON : poss\n",
      "name : NOUN : nsubj\n",
      "is : AUX : ROOT\n",
      "sujon : NOUN : attr\n",
      ". : PUNCT : punct\n",
      "I : PRON : nsubj\n",
      "am : AUX : ROOT\n",
      "a : DET : det\n",
      "software : NOUN : compound\n",
      "engineer : NOUN : attr\n"
     ]
    }
   ],
   "source": [
    "# Its syntactic dependency\n",
    "for token in doc:\n",
    "    print(token.text,\":\",token.pos_,\":\",token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa265f99-9a51-4e37-bde4-247895bba80e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google       :PROPN nsubj\n",
      "plans       :VERB ROOT\n",
      "to       :PART aux\n",
      "launch       :VERB xcomp\n",
      "new       :ADJ amod\n",
      "AI       :PROPN compound\n",
      "products       :NOUN dobj\n",
      "in       :ADP prep\n",
      "2025       :NUM pobj\n",
      ".       :PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "### Parsing Another Sentence\n",
    "text = \"Google plans to launch new AI products in 2025.\"\n",
    "doc = nlp(text)\n",
    "for t in doc:\n",
    "    print(f'{t.text}       :{t.pos_} {t.dep_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84ce2bc4-1b1b-4cab-91c7-7ddb9fc6d756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She       :PRON nsubj\n",
      "enjoys       :VERB ROOT\n",
      "reading       :VERB xcomp\n",
      "books       :NOUN dobj\n",
      "and       :CCONJ cc\n",
      "watching       :VERB conj\n",
      "movies       :NOUN dobj\n",
      ".       :PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "### Parsing a sentence with conjunction\n",
    "text = \"She enjoys reading books and watching movies.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(f'{token.text}       :{token.pos_} {token.dep_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaf870b4-649a-4352-8c3d-ac6cd7af5e93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite SCONJ prep\n",
      "the DET det\n",
      "rain NOUN pobj\n",
      ", PUNCT punct\n",
      "the DET det\n",
      "match NOUN nsubj\n",
      "continued VERB ROOT\n",
      "as SCONJ mark\n",
      "scheduled VERB advcl\n",
      "and CCONJ cc\n",
      "the DET det\n",
      "team NOUN nsubj\n",
      "won VERB conj\n",
      "by ADP prep\n",
      "3 NUM nummod\n",
      "goals NOUN pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "#  Parsing a complex sentence\n",
    "doc = nlp(\"Despite the rain, the match continued as scheduled and the team won by 3 goals.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7393834-0aad-4b33-a929-d2ecc62893a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det\n",
      "CEO NOUN nsubj\n",
      "said VERB ROOT\n",
      ", PUNCT punct\n",
      "\" PUNCT punct\n",
      "We PRON nsubj\n",
      "are AUX aux\n",
      "expanding VERB ccomp\n",
      "our PRON poss\n",
      "business NOUN dobj\n",
      "internationally ADV advmod\n",
      ". PUNCT punct\n",
      "\" PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Pasing a sentence with quotes\n",
    "doc = nlp('The CEO said, \"We are expanding our business internationally.\"')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ceb11b14-5772-42e0-8b6e-6bb972b1be47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det\n",
      "CEO NOUN nsubj\n",
      "said VERB ROOT\n",
      ", PUNCT punct\n",
      "\" PUNCT punct\n",
      "We PRON nsubj\n",
      "are AUX aux\n",
      "expanding VERB ccomp\n",
      "our PRON poss\n",
      "business NOUN dobj\n",
      "internationally ADV advmod\n",
      ". PUNCT punct\n",
      "\" PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Parsing a sentence with quotes\n",
    "doc = nlp('The CEO said, \"We are expanding our business internationally.\"')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ce826-1d12-476d-8600-7799998ef5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
